import { OpenAI } from "openai";
import fs from "fs";
import path from "path";
import { cosineSimilarity } from "./similarity";

import { config } from "dotenv";

config(); // .env ã®èª­ã¿è¾¼ã¿

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

type ChunkData = {
  text: string;
  embedding: number[];
};

// ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‹ã‚‰embeddingç”Ÿæˆ
export async function getAnswer(question: string): Promise<string> {
  const questionEmbeddingRes = await openai.embeddings.create({
    model: "text-embedding-3-small",
    input: question,
  });

  const questionEmbedding = questionEmbeddingRes.data[0].embedding;

  // åŸ‹ã‚è¾¼ã¿æ¸ˆã¿ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
  const dataPath = path.join(__dirname, "../../data/embeddings.json");
  const chunks: ChunkData[] = JSON.parse(fs.readFileSync(dataPath, "utf-8"));

  // é¡ä¼¼åº¦ã®é«˜ã„ãƒãƒ£ãƒ³ã‚¯ã‚’ä¸Šä½3ä»¶æŠ½å‡ºï¼ˆâ˜… é¡ä¼¼åº¦ä»˜ãã§å‡ºåŠ›ï¼‰
  const similarChunks = chunks
    .map((chunk) => ({
      ...chunk,
      similarity: cosineSimilarity(chunk.embedding, questionEmbedding),
    }))
    .sort((a, b) => b.similarity - a.similarity)
    .slice(0, 3);

  // ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›: é¡ä¼¼ãƒãƒ£ãƒ³ã‚¯è¡¨ç¤ºï¼ˆâ˜…è¿½åŠ ï¼‰
  console.log("ğŸ” Top similar chunks:");
  similarChunks.forEach((chunk, index) => {
    console.log(`\n#${index + 1} [score: ${chunk.similarity.toFixed(4)}]`);
    console.log(chunk.text);
  });

  const context = similarChunks.map((c) => c.text).join("\n---\n");

  // GPTã«å›ç­”ã‚’ç”Ÿæˆã•ã›ã‚‹
  const completion = await openai.chat.completions.create({
    model: "gpt-4",
    messages: [
      {
        role: "system",
        content: "ä»¥ä¸‹ã®æ–‡æ›¸ã‚’å‚è€ƒã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚",
      },
      {
        role: "user",
        content: `å‚è€ƒæ–‡æ›¸:\n${context}\n\nè³ªå•:\n${question}`,
      },
    ],
  });

  return (
    completion.choices[0].message.content || "å›ç­”ãŒç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
  );
}
